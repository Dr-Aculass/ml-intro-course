Prework: Supervised Machine Learning Potpourri
======

Agenda
-----

- Grid Search
- Random Forestâ„¢, out-of-bag samples 
- Regression variety of tree-based methods
- Handling unbalanced data
- "No Free Lunch" (NFL) theorem
- How to compare ML models

Required
------

- Review 8.1.1 Regression Trees from [Introduction to Statistical Learning (ISL)](https://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf) 
- Review 8.2 Bagging, Random Forests, Boosting from [Introduction to Statistical Learning (ISL)](https://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf) 
- The Mechanics of Machine Learning by Terence Parr and Jeremy Howard
    - From [Training an initial model](https://mlbook.explained.ai/prep.html#sec:3.4) to end
- [7 techniques to handle imbalanced data](https://www.kdnuggets.com/2017/06/7-techniques-handle-imbalanced-data.html)
- 6.1.3 Choosing the Optimal Model from [Introduction to Statistical Learning (ISL)](https://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf) 
- [The No Free Lunch Theorem](https://www.coursera.org/lecture/guided-tour-machine-learning-finance/the-no-free-lunch-theorem-a0rXt) (8 minutes)
- [No Free Lunch Theorem](https://medium.com/@javafolabi/no-free-lunch-theorem-what-you-should-watch-out-for-when-developing-your-algorithms-e9abff4c1d99)

Challenge
-----

- [Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)
- [How to handle Imbalanced Classification Problems in machine learning?](https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/)
- [5 Regression Loss Functions All Machine Learners Should Know](https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0)
